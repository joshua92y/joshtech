# app/utils/scheduler.py
from apscheduler.schedulers.background import BackgroundScheduler
from .ping_flyio import ping_render
from pathlib import Path
import logging
import asyncio
import time
import os
from html2image import Html2Image
import boto3
from botocore.client import Config
import httpx
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)
scheduler = BackgroundScheduler()

TMP_DIR = Path("tmp")
TTL_SECONDS = int(os.getenv("TMP_TTL_SECONDS", "300"))  # 5ë¶„
CLEANUP_INTERVAL_MIN = int(os.getenv("CLEANUP_INTERVAL_MIN", "5"))


def clean_tmp_folder():
    now = time.time()
    deleted = 0

    for file in TMP_DIR.glob("*"):
        if file.is_file() and now - file.stat().st_mtime > TTL_SECONDS:
            try:
                file.unlink()
                deleted += 1
            except Exception:
                logger.exception(f"âŒ {file} ì‚­ì œ ì‹¤íŒ¨")
    if deleted:
        logger.info(f"ğŸ§¹ {deleted}ê°œ ì„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")


# í™˜ê²½ ë³€ìˆ˜
R2_ENDPOINT = os.getenv(
    "R2_ENDPOINT",
    "https://91738ffff95834c5972f1a92aac416a6.r2.cloudflarestorage.com/joshtech",
)
R2_BUCKET = os.getenv("R2_BUCKET", "joshtech")
R2_ACCESS_KEY = os.getenv("R2_ACCESS_KEY", "91738ffff95834c5972f1a92aac416a6")
R2_SECRET_KEY = os.getenv(
    "R2_SECRET_KEY", "8d3446847d630f900e2521d0efc35a5cd5f92e50cd620987cdbd85f33978f070"
)
DJANGO_API = os.getenv(
    "DJANGO_API_URL", "https://your-django-api.com/api/files/"
)  # Django ë°±ì—”ë“œì—ì„œ ìš´ì˜ ì¤‘ì¸ íŒŒì¼ ë©”íƒ€ë°ì´í„° APIì˜ Base URLì…ë‹ˆë‹¤.

# R2 í´ë¼ì´ì–¸íŠ¸
s3 = boto3.client(
    "s3",
    endpoint_url=R2_ENDPOINT,
    aws_access_key_id=R2_ACCESS_KEY,
    aws_secret_access_key=R2_SECRET_KEY,
    config=Config(signature_version="s3v4"),
    region_name="auto",
)


async def clean_soft_deleted_files():
    async with httpx.AsyncClient() as client:
        try:
            # âœ… 1. Djangoì—ì„œ ì‚­ì œ ëŒ€ê¸° íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
            res = await client.get(DJANGO_API + "deletion-pending/")
            res.raise_for_status()
            to_delete = res.json()
        except Exception as e:
            logger.exception(f"âŒ ì‚­ì œ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return

        deleted_ids = []

        # âœ… 2. R2ì—ì„œ ì‹¤ì œ ì‚­ì œ ìˆ˜í–‰
        for item in to_delete:
            key = item["key"]
            pk = item["id"]
            try:
                s3.delete_object(Bucket=R2_BUCKET, Key=key)
                deleted_ids.append(pk)
                logger.info(f"âœ… ì‚­ì œ ì™„ë£Œ: {key}")
            except Exception as e:
                logger.exception(f"âŒ R2 ì‚­ì œ ì‹¤íŒ¨: {key} - {e}")

        # âœ… 3. Djangoì— ì‚­ì œ ì™„ë£Œ ë³´ê³ 
        if deleted_ids:
            try:
                res = await client.post(
                    DJANGO_API + "deletion-complete/", json={"ids": deleted_ids}
                )
                res.raise_for_status()
                logger.info(f"ğŸ§¹ Djangoì— ì‚­ì œ ì™„ë£Œ ë³´ê³ : {len(deleted_ids)}ê±´")
            except Exception as e:
                logger.exception(f"âŒ Django ì‚­ì œ ë³´ê³  ì‹¤íŒ¨: {e}")


def start():
    scheduler.add_job(
        func=lambda: asyncio.run(ping_render()),
        trigger="interval",
        minutes=5,
        id="ping_render",
        replace_existing=True,
    )
    scheduler.add_job(
        func=clean_tmp_folder,
        trigger="interval",
        minutes=CLEANUP_INTERVAL_MIN,
        id="tmp_cleanup",
        replace_existing=True,
    )

    scheduler.add_job(
        func=lambda: asyncio.run(clean_soft_deleted_files()),
        trigger="interval",
        minutes=10,
        id="r2_cleanup",
    )
    scheduler.start()
    logger.info("âœ… APScheduler started for all jobs.")
